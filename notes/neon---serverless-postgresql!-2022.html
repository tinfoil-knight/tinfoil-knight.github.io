<!DOCTYPE html>
<html><head><title>Neon - Serverless PostgreSQL! (2022)</title><meta charset="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:title" content="Neon - Serverless PostgreSQL! (2022)"/><link rel="icon" href="../static/favicon.ico"/><meta name="generator" content="Quartz"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link href="../index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=Open Sans:wght@400;700&amp;family=Spectral:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap" rel="stylesheet" type="text/css" spa-preserve/><script src="../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../static/contentIndex.json").then(data => data.json())</script></head><body data-slug="notes/neon---serverless-postgresql!-2022"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h1 class="page-title "><a href="..">Machines Fail</a></h1><div class="spacer mobile-only"></div><div class="search "><div id="search-icon"><p>Search</p><div></div><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search</title><desc id="desc">Search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></div><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="results-container"></div></div></div></div><div class="darkmode "><input class="toggle" id="darkmode-toggle" type="checkbox" tabindex="-1"/><label id="toggle-label-light" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve"><title>Light mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg></label><label id="toggle-label-dark" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve"><title>Dark mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></label></div></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container " aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../notes/">notes</a></div></nav><h1 class="article-title ">Neon - Serverless PostgreSQL! (2022)</h1><p class="content-meta ">Mar 25, 2024 | 2812 words</p><ul class="tags "><li><a href="../tags/db" class="internal tag-link">#db</a></li><li><a href="../tags/talks" class="internal tag-link">#talks</a></li><li><a href="../tags/cmudb-seminar" class="internal tag-link">#cmudb-seminar</a></li></ul><div class="content-frontmatter"><div style="list-style: none; margin-left: 0; padding-left: 0;">Source : <a href="https://www.youtube.com/watch?v=rES0yzeERns" class="external" style="color: inherit;">https://www.youtube.com/watch?v=rES0yzeERns</a></div><div style="list-style: none; margin-left: 0; padding-left: 0;">From : <span>Heikki Linnakangas</span></div></div><div class="toc "><button type="button" id="toc" class="collapsed"><h3>Table of Contents</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div id="toc-content"><ul class="overflow"><li class="depth-0"><a href="#what-is-neon" data-for="what-is-neon">What is Neon?</a></li><li class="depth-0"><a href="#separation-of-storage-and-compute" data-for="separation-of-storage-and-compute">Separation of Storage and Compute</a></li><li class="depth-0"><a href="#storage-engine" data-for="storage-engine">Storage Engine</a></li><li class="depth-0"><a href="#storage-format" data-for="storage-format">Storage Format</a></li><li class="depth-0"><a href="#qa" data-for="qa">Q/A</a></li><li class="depth-0"><a href="#appendix" data-for="appendix">Appendix</a></li></ul></div></div></div></div><article class="popover-hint"><p>Heikki is the co-founder of Neon &amp; a long-time PostgreSQL committer.</p>
<h2 id="what-is-neon">What is Neon?<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#what-is-neon" class="internal alias"> §</a></h2>
<ul>
<li>New storage system for Postgres</li>
<li>Storage and compute are separated</li>
<li>Multi-tenant storage
<ul>
<li>One storage layer that is shared across all customers and databases</li>
<li>Shared cache</li>
</ul>
</li>
<li>Single-tenant compute (Runs in K8s containers / VMs)
<ul>
<li>Future plan: BYO Postgres with specific version and extensions installed</li>
</ul>
</li>
<li>Cheap copy-on-write branching and time-travel query</li>
<li>Single-writer system i.e. single primary that’s generating log &amp; processing updates at any given time</li>
<li>Doesn’t try to solve the multi-master problem or conflicts across regions</li>
<li>Postgres compatibility
<ul>
<li>Currently, they’ve modified low-level storage in Postgres (read, write a page) so that those requests could be sent to their storage</li>
<li>Other things like Planner, Executor, index types, MVCC hasn’t been changed</li>
<li><a href="https://github.com/neondatabase/neon/blob/3220f830b7fbb785d6db8a93775f46314f10a99b/docs/core_changes.md" class="external alias">Postgres Core Changes</a></li>
</ul>
</li>
</ul>
<h2 id="separation-of-storage-and-compute">Separation of Storage and Compute<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#separation-of-storage-and-compute" class="internal alias"> §</a></h2>
<p><img src="../attachments/pasted-image-20240325030634.png" width="auto" height="auto"/></p>
<ul>
<li>Compute = PostgreSQL running in a VM</li>
<li>Storage = Neon storage system
<ul>
<li>Written in Rust</li>
</ul>
</li>
<li>pg streams WAL to the safekeepers
<ul>
<li>pg has support for stream replication (used to stream WAL from primary to replica) which they modified to stream the WAL to their storage system.</li>
</ul>
</li>
<li>pg reads pages from pageservers over network instead of local disk</li>
<li>write() in pg is a no-op. They just throw the page away &amp; it’s queried by the storage system (pageserver) using WAL if needed again
<ul>
<li>Don’t need to do traditional checkpointing since writing is a no-op. There’s no need to flush everything to disk in Neon.</li>
<li>Still let pg run checkpoint since it performs other functions than just flushing to disk but they don’t flush pages to disk.</li>
<li>Local disk is only used for temporary files, sorting etc. Data is wiped when Postgres is restarted.</li>
</ul>
</li>
<li>Why separate compute &amp; storage?
<ul>
<li>Compute can be shut down completely &amp; started quickly
<ul>
<li>Current startup time is 4s (includes launching the VM or K8s container, setting connection to storage &amp; replying back to client)</li>
</ul>
</li>
<li>Same storage can be shared by multiple read-only nodes</li>
<li>Scale independently</li>
<li>Cloud storage is cheap
<ul>
<li>Neon uses S3 or S3-compatible stores</li>
</ul>
</li>
</ul>
</li>
<li>Q/A : On the server-side when you boot up, do you pre-fetch anything in the buffer pool?
<ul>
<li>Nothing currently. The storage system does have its own cache so there’ll be any data in there if you recently re-started.</li>
<li>There are pg extensions to pre-warm the cache that are compatible with Neon. (Probably <a href="https://www.postgresql.org/docs/current/pgprewarm.html" class="external alias">pg-prewarm</a>)
<ul>
<li>But this brings in all the pages and not the ones present at last shutdown.</li>
</ul>
</li>
</ul>
</li>
<li>Q/A : Is the server cache the WAL or materialized pages?
<ul>
<li>Both.</li>
</ul>
</li>
</ul>
<h3 id="write-path">Write Path<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#write-path" class="internal alias"> §</a></h3>
<ul>
<li>3 safe-keeper nodes running at all times</li>
<li>Consensus algorithm based on Paxos
<ul>
<li>Wait for majority to acknowledge txn. commit before sending acknowledgement to original client</li>
</ul>
</li>
<li>Ensures durability of recent txn. (This is pretty much what safe-keepers are for)</li>
<li>Safe-keepers have local SSDs for storing WAL</li>
<li>Detour : Postgres WAL
<ul>
<li>Classic area-style representation</li>
<li>Physical, stores updated to 8kB pages</li>
<li>Mix of page images &amp; incremental updates
<ul>
<li>Doesn’t store statements</li>
</ul>
</li>
<li>No UNDO log, only REDO</li>
</ul>
</li>
<li>Page-servers
<ul>
<li>Key of the storage system</li>
<li>After log is durable in safe-keepers, it’s streamed to page-servers</li>
<li>Processes the WAL into a format (that lets them quickly find WAL records of a particular page) which is then written into immutable files on disk</li>
<li>Uploads files to cloud storage</li>
<li>Keep a copy in page-server for caching</li>
<li>Local SSDs for caching</li>
</ul>
</li>
<li>Durability
<ul>
<li>Recent WAL is made durable in safe-keepers</li>
<li>Older WAL is uploaded to cloud storage in processed format</li>
<li>Page-servers are disposable</li>
</ul>
</li>
</ul>
<h3 id="read-path">Read Path<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#read-path" class="internal alias"> §</a></h3>
<ul>
<li>Page-servers
<ul>
<li>Replays WAL to reconstruct pages on demand</li>
<li>Can reconstruct any page at any point in time
<ul>
<li>Keeps all history upto some retention period</li>
<li>Instead of traditional backups &amp; WAL archive, they store data in their own format in cloud for random access</li>
</ul>
</li>
<li>Request for Page from pg -> Page-server finds the last image &amp; replays the log of that single page -> Sends back the page</li>
</ul>
</li>
<li>Q/A: Does the page-server wait for the safe-keeper to send it or requests it when it doesn’t have a particular log record?
<ul>
<li>When pg requests the page at a particular LSN, if the page-server doesn’t have it yet, it’ll wait</li>
</ul>
</li>
<li>Q/A: Does pg maintain internally that for page 123, it expects this LSN or is it something you’re adding?
<ul>
<li>We’ve to add that.</li>
<li>Wasn’t needed for correctness. The primary node could request the latest LSN it wrote &amp; it’d be correct but that’d cause a perf. problem because anytime you read anything from the page-server, you’d need to wait to get the latest version and most of the time there were no changes to that version.</li>
<li>We had to add a cache that tracks LSN numbers of pages evicted from cache. (Last 1000 evicted pages w/ LRU)</li>
</ul>
</li>
</ul>
<h3 id="control-plane--proxy">Control Plane &amp; Proxy<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#control-plane--proxy" class="internal alias"> §</a></h3>
<p><img src="../attachments/pasted-image-20240325033014.png" width="auto" height="auto"/></p>
<ul>
<li>When the client connects, it first connects to a proxy.</li>
<li>Proxy intercepts the connection, performs auth &amp; queries the control plane about the running pg instance and starts one if none is running for the client.
<ul>
<li>VMs are shut down after 5mins of inactivity.</li>
</ul>
</li>
<li>Control plane starts &amp; stops compute nodes
<ul>
<li>Also provides the web UI &amp; user-facing API for creating DBs, branches etc.</li>
</ul>
</li>
<li>Q/A: Is the proxy written from scratch or did you use pgBouncer or something similar?
<ul>
<li>From scratch. We don’t use the proxy for connection pooling. We use it as a pass-through.</li>
</ul>
</li>
</ul>
<h2 id="storage-engine">Storage Engine<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#storage-engine" class="internal alias"> §</a></h2>
<ul>
<li>
<p>Traditional Point-in-Time Recovery</p>
<ul>
<li>Take periodic backups and archive WAL to durable storage</li>
<li>To restore
<ul>
<li>Restore last backup before the point-in-time</li>
<li>Replay all the log</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Neon does this at page granularity</p>
<ul>
<li>Keeps backup of individual pages &amp; stores WAL records of these individual pages</li>
<li>WAL contains a mix of full page images &amp; incremental WAL records
<ul>
<li>pg prefers to write the full image of a page in case of bulk loading, building an index etc. otherwise it’ll mostly store the incremental updates</li>
</ul>
</li>
<li>To reconstruct a page version
<ul>
<li>Find the last image of the page</li>
<li>Replay all the WAL records on top of it</li>
</ul>
</li>
<li>To make this perform:
<ul>
<li>Page-server reorders &amp; indexes the WAL</li>
<li>Materialize &amp; store additional page images
<ul>
<li>pg might have a lot of updates for a page so the page-server decides to store some additional page images so that the entire log doesn’t have to be played back when the page is queried</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Q/A</p>
<ul>
<li>Do you store only the latest version of a page in the page-server or could you materialize multiple ones?
<ul>
<li>We can reconstruct any page version upto the retention period.</li>
</ul>
</li>
<li>Do you do any compression on the physical storage?
<ul>
<li>Not currently. We plan to do it.</li>
</ul>
</li>
<li>If you don’t set fill-factor right, that’s more just like an interaction with auto-vacuum where updates could span multiple pages &amp; you just need the auto-vacuum to clean that up but with this system we’re keeping page versions does that mean you get a bunch of write amplification if you don’t have your fill-factor knob set right?
<ul>
<li>fill-factor: how full pages will be packed (in table or index)</li>
<li>Vacuum will create new versions of these pages but that’s okay since the WAL records are quire small so Vacuum will create new versions of these pages.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>GetPage@LSN</p>
<ul>
<li>When pg needs to read a page, it sends a request to page-server : GetPage(RelFileNode, block #, LSN)
<ul>
<li>Primary node uses “last-evicted LSN” of the page
<ul>
<li>Last-evicted LSN is loosely tracked for each page</li>
</ul>
</li>
<li>Read-only node can be anchored at an old LSN
<ul>
<li>For doing a time-travel query, for eg: if you want to recover to the point where you say dropped the table then you launch a pg node and point it to the page-server &amp; you give it the LSN that you want to read the data &amp; pg will send all requests at that specific LSN &amp; you can see the data as it was at that point of time</li>
</ul>
</li>
<li>Read-only node that follows the primary
<ul>
<li>There’s a cache invalidation problem &amp; if you’ve a read-only replica that’s following the primary, the read-only node will still need to follow the WAL from the primary to figure out which pages are being modified because it might’ve a version of those pages in cache &amp; it needs to throw them away.</li>
<li>From the page-server side, it looks like the read-only node requests the pages with an increasing LSN as it tracks the primary</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="storage-engine--key-value-store">Storage Engine : Key-Value Store<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#storage-engine--key-value-store" class="internal alias"> §</a></h3>
<ul>
<li>Key: relation id + block number + LSN
<ul>
<li>Relation ID tells which table or index a block belongs to</li>
</ul>
</li>
<li>Value: 8kB page or WAL record</li>
<li>Metadata key+value pairs are stored for tracking things like relation size</li>
<li>Q/A : What’s special about the multi-attribute key
<ul>
<li>We’re doing range queries when you request a page at particular LSN. We need to find the last version of the page &amp; it’s not a point lookup.</li>
<li>The LSN no. keeps incrementing as we digest new WAL. We don’t replace the old value. We add to it &amp; preserve the history too.</li>
</ul>
</li>
<li>Inspired by LSM</li>
<li>Immutable files
<ul>
<li>WAL is buffered in memory (in a BTree)</li>
<li>When ~1GB of WAL has accumulated, it’s written out to a new layer file (similar to an SSTable in LSMs)</li>
<li>Existing layer files are never modified</li>
<li>Old files can be merged &amp; compacted, by creating new files and deleting old ones</li>
</ul>
</li>
<li>All files are uploaded to cloud storage
<ul>
<li>And downloaded back on-demand, if missing locally</li>
</ul>
</li>
</ul>
<h4 id="why-not-use-an-existing-lsm-implementation">Why not use an existing LSM implementation?<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#why-not-use-an-existing-lsm-implementation" class="internal alias"> §</a></h4>
<ul>
<li>Need to access history
<ul>
<li>Used RocksDB in a earlier prototype &amp; use the block number + LSN as the key</li>
<li>Didn’t behave very well since when you keep accumulating new versions of a page, you insert new key-value pairs but when you do compaction, you move those existing keys to the next level &amp; so on but we didn’t want to do that since we’re not going to modify those keys &amp; there’s never any tombstone since we don’t remove anything. Write amplification was quite bad with this.</li>
<li>Many LSM tree implementation have support for snapshots and the capability to read older versions of key value pair &amp; they typically do that for MVCC &amp; Snapshot Isolation but they don’t really expose the functionality. Many of them wouldn’t allow using our LSN number or they’d only allow you to take a snapshot &amp; then read all of the data but it wouldn’t allow to take a snapshot in history &amp; they’d only keep the snapshot while the system is running.</li>
</ul>
</li>
<li>2 kinds of values: images &amp; deltas (= WAL records)</li>
<li>Need to control materialization
<ul>
<li>Some implementations allowed hooking into the compact/merge operation &amp; re-write some of the keys at that point but not all of the keys.</li>
</ul>
</li>
<li>Upload/download from cloud storage</li>
<li>Branching for cheap copy-on-write branches
<ul>
<li>This might’ve worked with other stores since it’s implemented at a higher level in our storage engine.</li>
<li>We create a new storage for each branch &amp; if you fall to the bottom of that storage w/o finding a version of that page, you look at the parents.</li>
</ul>
</li>
<li>Written in Rust or another memory-safe language
<ul>
<li>Since our storage system is multi-tenant, the buffer cache is shared across different DBs belonging to different customers &amp; we don’t want to have a segfault or leak data from one DB to another.</li>
</ul>
</li>
<li>We already have WAL &amp; many key-value stores come with a WAL which we don’t need</li>
</ul>
<h2 id="storage-format">Storage Format<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#storage-format" class="internal alias"> §</a></h2>
<p><img src="../attachments/pasted-image-20240325175452.png" width="auto" height="auto"/></p>
<ul>
<li>Consists of immutable files called layer files</li>
<li>2 kinds of layer files
<ul>
<li>Image layer: contains a snapshot of all key-value pairs in a key-range at one LSN
<ul>
<li>Created in background to speed up access and allow garbage collecting old data</li>
<li>Image layer creation every ~20 seconds</li>
</ul>
</li>
<li>Delta layer: contains all changes in a key and LSN range
<ul>
<li>If a key wasn’t modified, it’s not stored</li>
<li>Incoming WAL is written out as delta layers</li>
</ul>
</li>
</ul>
</li>
<li>2-D storage
<ul>
<li>X/Y :  block ID/LSN</li>
<li>Rectangles are delta layers</li>
<li>Horizontal <strong>bars</strong> are image layers</li>
<li>Each file is roughly the same size (~1GB which seems pretty good for dealing w/ cloud storage)</li>
</ul>
</li>
<li>Search
<ul>
<li>To re-construct a page version, GetPage@LSN needs to find the last image of the page &amp; all WAL records on top of it
<ul>
<li>Search starts at the given block # and LSN, visit layers (downwards) until you find an image</li>
<li>Delta layers may contain images</li>
<li>Search stops at image layers</li>
</ul>
</li>
<li>Search is downwards. Look into the layer file &amp; collect the WAL records for the particular key (if any) and so on until we hit the image layer which contains images of all the pages in the key-range.
<ul>
<li>We’ve the last image &amp; the WAL records now which can be replayed</li>
<li>If a full image is found in the delta layer, we can stop the search earlier</li>
</ul>
</li>
</ul>
</li>
<li>Processing incoming WAL
<ul>
<li>New delta layers are added to the top</li>
<li>Logs are re-ordered and stored in their format for faster lookups</li>
</ul>
</li>
<li>Compaction
<ul>
<li>Re-shuffles data in delta layers that contain all of the changes for a larger LSN range but smaller key- range
<ul>
<li>For better locality in searches
<ul>
<li>Since you’ve fewer files &amp; don’t need to visit too many layers</li>
<li>Might’ve got similar benefit with something like a bloom filter (but isn’t implemented yet)</li>
</ul>
</li>
<li>To aid in garbage collection (of frequently updated parts)</li>
</ul>
</li>
<li>Mentioned that they aren’t entirely sure about compaction for their use-case yet</li>
</ul>
</li>
<li>Garbage Collection
<ul>
<li>Removes old layer files that aren’t needed anymore</li>
</ul>
</li>
<li>Someone at Neon wrote a tool to visualise the cluster:<br/>
<img src="../attachments/pasted-image-20240325181518.png" width="auto" height="auto"/></li>
<li>Branching
<ul>
<li>Neon supports cheap, copy-on-write branches &amp; this is how they do backups.</li>
<li>When you read a key on the child branch &amp; it’s not found, continue to read it from the parent at the branch point.</li>
</ul>
</li>
<li>Open questions for Neon
<ul>
<li>When to materialize pages pre-emptively?
<ul>
<li>We don’t need to materialize until the compute requests the page.</li>
<li>If you’ve a workload that doesn’t fit into the cache in pg then you’d keep frequently requesting pages it wrote a while ago &amp; it’d affect your latency if we need to do a replay at that point. (It takes a few ms to collect the records &amp; do the replay)</li>
<li>They haven’t solved the problem of when they should request a page pre-emptively.</li>
<li>Q/A
<ul>
<li>When you decommission the compute layer every 5 mins, do you signal the page-server to cleanup the data?
<ul>
<li>We don’t currently.</li>
</ul>
</li>
<li>How do compute servers know which page-servers to read from?
<ul>
<li>The control plane keeps track of this. There is currently only 1 page-server for 1 database. It’s not currently sharded but we plan to do it in future.</li>
</ul>
</li>
<li>Do you find yourself more limited by network bandwidth or disk bandwidth for reading from page-servers?
<ul>
<li>One thing we ran into was the sequential scan speed. pg relies heavily on OS cache for sequential scans so when you’re scanning it’ll request page numbers one-by-one in order. The network round-trip for each individual page made this very slow for us so we added pre-fetching support.</li>
<li>In other workloads, we’ve to face the overhead of reconstructing the pages doing the WAL replay if there were a lot of changes in the page.</li>
<li>If you’ve a lot of layer files, we had a dumb algorithm for keeping track of what layer files exist which consumed a lot of CPU but we’re addressing that with a different data structure there.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>When to create image layers?</li>
<li>When to merge delta layers?</li>
</ul>
</li>
</ul>
<h2 id="qa">Q/A<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#qa" class="internal alias"> §</a></h2>
<ul>
<li>What % of DBs in Neon are swapped out?
<ul>
<li>We try to keep everything in the page-server right now.  We only rely on swapping out if we have to kill the page-server and reload it. We don’t have enough data to need to swap things out. We’ve had the service running for a few months &amp; that hasn’t been enough time to create enough data to swap anything else.</li>
<li>For the compute layers, we’ve b/w 50 and 100 active computes at any given time. We’ve about 3000 registered users.</li>
</ul>
</li>
<li>You mentioned that it takes 4s if you’ve a decommissioned instance &amp; you connect to it. How does this compares against serverless Postgres from Amazon?
<ul>
<li>Amazon doesn’t scale down to 0. Don’t know how much time it takes for them to startup.</li>
<li>For us, it takes ~1s to spin up the pod, few 100 ms to download a “base backup” (pg database directory w/o the data since the data is downloaded separately). We run some queries to check if pg works. We add a record to internal DB through control-plane for book-keeping to remember that we started this pod. And then there’s the round-trip latency going to the client.
<ul>
<li>pg database directory is needed so that pg can find anything that’s not just a table or index.</li>
<li>Goal is to get it down to 1s.</li>
</ul>
</li>
</ul>
</li>
<li>Since you modified the pg storage system &amp; pg relies on OS page cache so is there anything you had to change about the assumption that pg makes about having an OS page cache?
<ul>
<li>The sequential scan was one thing since pg depended on OS to do the read-ahead. We don’t get the benefit of the OS page cache.</li>
</ul>
</li>
</ul>
<h2 id="appendix">Appendix<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#appendix" class="internal alias"> §</a></h2>
<ul>
<li><a href="https://github.com/neondatabase/neon" class="external">https://github.com/neondatabase/neon</a></li>
<li><a href="https://neon.tech/" class="external">https://neon.tech/</a></li>
</ul></article></div><div class="right sidebar"></div></div><footer class><hr/><ul style="display:flex;"><li><a href="https://github.com/tinfoil-knight">GitHub</a></li><li><a href="https://twitter.com/machines_fail">Twitter</a></li><li><a href="https://www.linkedin.com/in/kunal-kundu/">LinkedIn</a></li><li style="flex-grow:1;text-align:right;">Built with <a href="https://quartz.jzhao.xyz/">Quartz</a></li></ul></footer></div></body><script type="application/javascript">// quartz/components/scripts/quartz/components/scripts/callout.inline.ts
function toggleCallout() {
  const outerBlock = this.parentElement;
  outerBlock.classList.toggle(`is-collapsed`);
  const collapsed = outerBlock.classList.contains(`is-collapsed`);
  const height = collapsed ? this.scrollHeight : outerBlock.scrollHeight;
  outerBlock.style.maxHeight = height + `px`;
  let current = outerBlock;
  let parent = outerBlock.parentElement;
  while (parent) {
    if (!parent.classList.contains(`callout`)) {
      return;
    }
    const collapsed2 = parent.classList.contains(`is-collapsed`);
    const height2 = collapsed2 ? parent.scrollHeight : parent.scrollHeight + current.scrollHeight;
    parent.style.maxHeight = height2 + `px`;
    current = parent;
    parent = parent.parentElement;
  }
}
function setupCallout() {
  const collapsible = document.getElementsByClassName(
    `callout is-collapsible`
  );
  for (const div of collapsible) {
    const title = div.firstElementChild;
    if (title) {
      title.removeEventListener(`click`, toggleCallout);
      title.addEventListener(`click`, toggleCallout);
      const collapsed = div.classList.contains(`is-collapsed`);
      const height = collapsed ? title.scrollHeight : div.scrollHeight;
      div.style.maxHeight = height + `px`;
    }
  }
}
document.addEventListener(`nav`, setupCallout);
window.addEventListener(`resize`, setupCallout);
</script><script type="module">
          import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';
          const darkMode = document.documentElement.getAttribute('saved-theme') === 'dark'
          mermaid.initialize({
            startOnLoad: false,
            securityLevel: 'loose',
            theme: darkMode ? 'dark' : 'default'
          });
          document.addEventListener('nav', async () => {
            await mermaid.run({
              querySelector: '.mermaid'
            })
          });
          </script><script src="../postscript.js" type="module"></script></html>