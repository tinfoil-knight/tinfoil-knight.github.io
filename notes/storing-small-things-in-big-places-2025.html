<!DOCTYPE html>
<html><head><title>Storing Small Things in Big Places (2025)</title><meta charset="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:title" content="Storing Small Things in Big Places (2025)"/><link rel="icon" href="../static/favicon.ico"/><meta name="generator" content="Quartz"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link href="../index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=Open Sans:wght@400;700&amp;family=Spectral:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap" rel="stylesheet" type="text/css" spa-preserve/><script src="../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../static/contentIndex.json").then(data => data.json())</script></head><body data-slug="notes/storing-small-things-in-big-places-2025"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h1 class="page-title "><a href="..">Machines Fail</a></h1><div class="spacer mobile-only"></div><div class="search "><div id="search-icon"><p>Search</p><div></div><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search</title><desc id="desc">Search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></div><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="results-container"></div></div></div></div><div class="darkmode "><input class="toggle" id="darkmode-toggle" type="checkbox" tabindex="-1"/><label id="toggle-label-light" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve"><title>Light mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg></label><label id="toggle-label-dark" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve"><title>Dark mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></label></div></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container " aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../notes/">notes</a></div></nav><h1 class="article-title ">Storing Small Things in Big Places (2025)</h1><p class="content-meta ">May 18, 2025 | 1134 words</p><ul class="tags "><li><a href="../tags/db" class="internal tag-link">#db</a></li><li><a href="../tags/talks" class="internal tag-link">#talks</a></li></ul><div class="content-frontmatter"><div style="list-style: none; margin-left: 0; padding-left: 0;">Source : <a href="https://www.youtube.com/watch?v=eRsD8uSAi0s" class="external" style="color: inherit;">https://www.youtube.com/watch?v=eRsD8uSAi0s</a></div><div style="list-style: none; margin-left: 0; padding-left: 0;">From : <span>Carl Sverre</span></div></div><div class="toc "><button type="button" id="toc" class="collapsed"><h3>Table of Contents</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div id="toc-content"><ul class="overflow"><li class="depth-0"><a href="#physical-organization" data-for="physical-organization">Physical Organization</a></li><li class="depth-0"><a href="#architecture" data-for="architecture">Architecture</a></li><li class="depth-0"><a href="#appendix" data-for="appendix">Appendix</a></li></ul></div></div></div></div><article class="popover-hint"><p>Carl Sverre</p>
<ul>
<li>Author of SQLSync (multi-player SQLite for local-first apps).</li>
<li>Worked at SingleStore earlier.</li>
</ul>
<p>Motivation</p>
<ul>
<li>While SQLSync got popular, Carl realized that the backend wouldn’t scale when he was trying to turn SQLSync into a product.</li>
<li>What would be the ideal backend to make SQLSync work?
<ul>
<li>Transactional object storage providing lazy partial edge replication at global scale.</li>
</ul>
</li>
</ul>
<p>Lazy</p>
<ul>
<li>Clients choose when to sync.</li>
<li>Changes are rolled up, allowing clients to fast forward.<br/>
Partial</li>
<li>Clients choose what to sync.</li>
<li>Clients learn what changes via sync and pull the actual data separately.<br/>
Edge</li>
<li>Clients choose where to sync.</li>
<li>Client is lightweight and embedded in the application.<br/>
Replication</li>
<li>Clients see consistent snapshots of data. (internal consistency, snapshot isolation)</li>
<li>Optimized for cost and reliability (at the cost of performance).</li>
</ul>
<p>Carl ended up building Graft since he couldn’t find anything that met all his requirements.</p>
<h2 id="physical-organization">Physical Organization<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#physical-organization" class="internal alias"> §</a></h2>
<ul>
<li>Data is organized into Volumes.</li>
<li>Volumes are sparse ordered sets of Pages.
<ul>
<li>SQLite stores data in BTrees which map down to Pages.</li>
<li>Graft Pages are small (4KB).</li>
<li>For this talk, a page is a fixed-size block of bytes w/ the size being a power of 2.</li>
</ul>
</li>
</ul>
<h2 id="architecture">Architecture<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#architecture" class="internal alias"> §</a></h2>
<p><img src="../attachments/pasted-image-20250518021102.png" width="auto" height="auto"/></p>
<ul>
<li>Page Store: stores pages durably on an object store.</li>
<li>Meta Store : maintain commit history of a volume.
<ul>
<li>Metadata of snapshots (version no., set of segments and offsets that’ve changed inside of those segments).</li>
<li>Performance is limited by object storage. SQLSync isn’t intended for realtime high performance but for async offline-first replication.</li>
</ul>
</li>
</ul>
<h3 id="client-uploads-changed-pages-durability-phase">Client uploads changed pages (Durability Phase)<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#client-uploads-changed-pages-durability-phase" class="internal alias"> §</a></h3>
<p><img src="../attachments/pasted-image-20250518024834.png" width="auto" height="auto"/></p>
<ul>
<li>Page Store is hosted on <a href="https://fly.io/" class="external alias">Fly.io</a>. Client can connect to any page store world-wide. Page store instances buffer up many pages from different writers into segments. Writes are buffered and flushed every second.</li>
<li>The object store returns a list of segment IDs that contain the pages corresponding to the client’s write request along w/ which offsets the client uploaded in each segment. Eg: Upload 10 pages which get split into say 2 segments. Offsets 1-5 landed in the first segment and so on.</li>
<li>At this point, the data has been fully synced to object storage.</li>
</ul>
<h3 id="client-commits-segment-metadata">Client commits segment metadata<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#client-commits-segment-metadata" class="internal alias"> §</a></h3>
<p><img src="../attachments/pasted-image-20250518025930.png" width="auto" height="auto"/></p>
<ul>
<li>How do we commit data into the next snapshot version of the volume?</li>
<li>Client takes an array of segment metadata (segment and page offsets) and sends it to the meta-store which is responsible for ensuring that the version no. of a volume is monotonic and atomic.</li>
<li>Only a single writer commits on a particular snapshot version.</li>
<li>Eg: Client is at v1. Wants to make a write and transition to v2. It’ll send the segment metadata to the meta store and if v1 is the current latest version on cloud then meta-store will commit the change. Uses CAS (Compare-and-Swap) on object store. If it works then the meta-store confirms that snapshot is committed to the client.</li>
<li>If there’s a conflict, the meta-store denies the request. The client has a list of segments &amp; all the pages it wrote. It also retrieves the new snapshot version from the server and it can see what offsets have changed.
<ul>
<li>The client can do a variant of MVCC locally because it has its own read and write set. It can check if the pages uploaded to the page store are valid or if they need to be recomputed. If the client decides that pages need to be updated, it can replay the commit on the new snapshot version.</li>
<li>Doing client-side MVCC allows keeping the page store distributed instead of centralizing it.</li>
</ul>
</li>
<li>Q/A
<ul>
<li>Are you actually waiting for the write to flush entirely to S3?
<ul>
<li>Yes. Potentially in the future, a raft consensus layer w/ fast writers on NVMe disks can respond immediately.</li>
</ul>
</li>
<li>How tightly coupled are Graft pages and SQLite pages? Can a SQLite page cross multiple Graft pages? Would Graft work for other DBs?
<ul>
<li>Technically, anything that can be mapped to the 4KB page size of Graft can be used w/ it. He has used it w/ key-value store, file-systems. Mis-aligned pages will have overhead though.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="client-pulls-a-set-of-changed-page-offsets">Client pulls a set of changed page offsets<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#client-pulls-a-set-of-changed-page-offsets" class="internal alias"> §</a></h3>
<p><img src="../attachments/pasted-image-20250521164607.png" width="auto" height="auto"/></p>
<ul>
<li>Never need to store more data than what describes changing every page in the set because if the same page is changed multiple times, we only need to know that it’s changed and not that it changed multiple times.</li>
<li>Client requests changes since a version. Meta Store is stateless so it first refreshes the commit index and then computes all of the offsets that’ve changed b/w the original version and the latest version.</li>
<li>If the volume is a 1000 pages, the max. data the client will receive is a 1000 <code>u32</code>’s and a single <code>u64</code>.</li>
</ul>
<h3 id="client-downloads-pages-as-needed">Client downloads pages as needed<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#client-downloads-pages-as-needed" class="internal alias"> §</a></h3>
<p><img src="../attachments/pasted-image-20250521165611.png" width="auto" height="auto"/></p>
<ul>
<li>Once the client receives the set, it knows that new versions of pages exist and it needs to retrieve the pages it wants to read (doesn’t need to read the rest but it can).</li>
<li>Client maintains a set of snapshots in its local state.</li>
<li>Some threads in an app might still be operating on a previously downloaded snapshot.</li>
<li>Graft allows the client to maintain local snapshots at different versions.</li>
<li>If a page@version isn’t available in the local Graft cache, the client requests the page from the pre-fetcher.
<ul>
<li>The pre-fetcher expands the requests for a single fetch into multiple based on patterns (like forward and reverse sequential reads, strided reads) using the <a href="https://www.usenix.org/system/files/atc20-maruf.pdf" class="external alias">Leap</a> algorithm.
<ul>
<li>strided : constant offset b/w consecutive reads.</li>
</ul>
</li>
</ul>
</li>
<li>The requests are then sent to the page store. Page store either has the segment cached in memory, NVMe disk or requests it from the object storage.</li>
</ul>
<p>Q/A</p>
<ul>
<li>Do you calculate roll-ups on the metadata read everytime?
<ul>
<li>Yes. When you do a poll, the metadata server calculates the rollups. To do this efficiently, a small set optimized (alternative to Roaring Bitmaps) is used.</li>
<li>Roaring Bitmaps is a compressed bitset. It doesn’t work well w/ small no. of bits that are highly sparse. So Carl wrote a compressed bitmap (<a href="https://github.com/orbitinghail/splinter-rs" class="external alias">Splinter</a>) which also allows extremely quick intersections and is zero-copy. Pages can be mapped from object storage directly to memory w/o any de-serialization. After verifying that the pages aren’t corrupt, they can be directly sent to and used by the client since it uses the same compressed bitset representation for calculations.</li>
</ul>
</li>
<li>What’s the relation b/w the pages and the actual files on S3? You mentioned batching for fewer requests.
<ul>
<li>Graft uses segments which is just a collection of pages by many clients, into many volumes &amp; at potentially different versions.</li>
<li>In the case where you’ve millions of volumes, each segment would have thousands of pages.</li>
<li>Future work: Like LSM trees that run on object storage, you’d want to merge and optimize data from sparse segments (different volumes) to segments with fewer (and larger) volumes. Files would be as dense as possible and optimized to read subset of segments into memory.</li>
</ul>
</li>
</ul>
<h2 id="appendix">Appendix<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#appendix" class="internal alias"> §</a></h2>
<ul>
<li><a href="https://github.com/orbitinghail/graft" class="external">https://github.com/orbitinghail/graft</a></li>
<li><a href="https://sqlsync.dev/posts/stop-syncing-everything/" class="external">https://sqlsync.dev/posts/stop-syncing-everything/</a></li>
</ul></article></div><div class="right sidebar"></div></div><footer class><hr/><ul style="display:flex;"><li><a href="https://github.com/tinfoil-knight">GitHub</a></li><li><a href="https://twitter.com/machines_fail">Twitter</a></li><li><a href="https://www.linkedin.com/in/kunal-kundu/">LinkedIn</a></li><li style="flex-grow:1;text-align:right;">Built with <a href="https://quartz.jzhao.xyz/">Quartz</a></li></ul></footer></div></body><script type="application/javascript">// quartz/components/scripts/quartz/components/scripts/callout.inline.ts
function toggleCallout() {
  const outerBlock = this.parentElement;
  outerBlock.classList.toggle(`is-collapsed`);
  const collapsed = outerBlock.classList.contains(`is-collapsed`);
  const height = collapsed ? this.scrollHeight : outerBlock.scrollHeight;
  outerBlock.style.maxHeight = height + `px`;
  let current = outerBlock;
  let parent = outerBlock.parentElement;
  while (parent) {
    if (!parent.classList.contains(`callout`)) {
      return;
    }
    const collapsed2 = parent.classList.contains(`is-collapsed`);
    const height2 = collapsed2 ? parent.scrollHeight : parent.scrollHeight + current.scrollHeight;
    parent.style.maxHeight = height2 + `px`;
    current = parent;
    parent = parent.parentElement;
  }
}
function setupCallout() {
  const collapsible = document.getElementsByClassName(
    `callout is-collapsible`
  );
  for (const div of collapsible) {
    const title = div.firstElementChild;
    if (title) {
      title.removeEventListener(`click`, toggleCallout);
      title.addEventListener(`click`, toggleCallout);
      const collapsed = div.classList.contains(`is-collapsed`);
      const height = collapsed ? title.scrollHeight : div.scrollHeight;
      div.style.maxHeight = height + `px`;
    }
  }
}
document.addEventListener(`nav`, setupCallout);
window.addEventListener(`resize`, setupCallout);
</script><script type="module">
          import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';
          const darkMode = document.documentElement.getAttribute('saved-theme') === 'dark'
          mermaid.initialize({
            startOnLoad: false,
            securityLevel: 'loose',
            theme: darkMode ? 'dark' : 'default'
          });
          document.addEventListener('nav', async () => {
            await mermaid.run({
              querySelector: '.mermaid'
            })
          });
          </script><script src="../postscript.js" type="module"></script></html>